{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","mount_file_id":"1RIcBiThE1yFwNq7GrmiWpCeyXVrDja6m","authorship_tag":"ABX9TyPFQafyfKMFRgdCGl9Cpkgd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# pytorch"],"metadata":{"id":"7lDN0D_DwDex"}},{"cell_type":"code","source":["import urllib\n","url, filename = (\"https://media.bunjang.co.kr/product/221232138_{cnt}_1681566135_w{res}.jpg\", \"shirts.jpg\")\n","try: urllib.URLopener().retrieve(url, filename)\n","except: urllib.request.urlretrieve(url, filename)"],"metadata":{"id":"D-gFj9smnbZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n","model.eval()"],"metadata":{"id":"DPV5mW52x7gM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","from torchvision import transforms\n","input_image = Image.open(filename)\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","input_tensor = preprocess(input_image)\n","input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","\n","# move the input and model to GPU for speed if available\n","if torch.cuda.is_available():\n","    input_batch = input_batch.to('cuda')\n","    model.to('cuda')\n","\n","with torch.no_grad():\n","    output = model(input_batch)\n","# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n","print(output[0])\n","# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n","probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","# print(probabilities)"],"metadata":{"id":"yQbisdQmnbfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download ImageNet labels\n","!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"],"metadata":{"id":"hRwCvlNynbjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the categories\n","with open(\"imagenet_classes.txt\", \"r\") as f:\n","    categories = [s.strip() for s in f.readlines()]\n","# Show top categories per image\n","top5_prob, top5_catid = torch.topk(probabilities, 5)\n","for i in range(top5_prob.size(0)):\n","    print(categories[top5_catid[i]], top5_prob[i].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ra5-XXF8nbmb","executionInfo":{"status":"ok","timestamp":1685620023377,"user_tz":-540,"elapsed":732,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"d2e5e53e-49ef-42bd-e814-349048961ce4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pajama 0.7874180674552917\n","apron 0.10574471205472946\n","swimming trunks 0.020261457189917564\n","bow tie 0.016007767990231514\n","sweatshirt 0.01297826785594225\n"]}]},{"cell_type":"markdown","source":["# pytorch transfer learning1"],"metadata":{"id":"jbYTHJvznbsk"}},{"cell_type":"code","source":["# -- torch._six 에러 생기면 최신 버전으로 업데이트 해주기 --\n","# !pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html -U"],"metadata":{"id":"HC1foY8_1tC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 개와 고양이 데이터 세트 다운로드\n","!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n","!unzip cats_and_dogs_filtered.zip"],"metadata":{"id":"yEcekdnOnE11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습에 필요한 라이브러리 불러오기\n","import torch\n","import torchvision\n","from torchvision import transforms, datasets, models\n","from torchsummary import summary\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# other\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","import time"],"metadata":{"id":"UtinfuNWEYCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=200\n","transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","])"],"metadata":{"id":"aBoLhjUWElEp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 가져오기\n","trainset = datasets.CIFAR10(root='dataset/',train=True,\n","                                        download=True,transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","testset = datasets.CIFAR10(root='dataset/',train=False,\n","                                       download=True,transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                          shuffle=False, num_workers=2)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiRRUThcD8Hd","executionInfo":{"status":"ok","timestamp":1685627341085,"user_tz":-540,"elapsed":7224,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"e172a302-eff6-4d73-8dc8-f0b18703bbce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 79356803.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/cifar-10-python.tar.gz to dataset/\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","test = iter(trainloader)\n","images, labels = next(test)\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# imshow(torchvision.utils.make_grid(images))\n","imshow(images[0])\n","print(classes[labels[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"BY-OdmMzEEqr","executionInfo":{"status":"ok","timestamp":1685625352920,"user_tz":-540,"elapsed":1015,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"cf0356ea-a69f-4f47-8992-674e1afbafe1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["car\n"]}]},{"cell_type":"code","source":["# 학습 세트에 적용할 데이터 변환을 설정\n","# 데이터 전처리\n","train_config = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor()\n","])\n","\n","# 테스트 세트에 적용할 데이터 변환을 설정\n","test_config = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor()\n","])"],"metadata":{"id":"4upkV5GknFQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n","model.eval()"],"metadata":{"id":"0--wsih61K5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델의 가중치를 더 이상 학습하지 않도록 설정.\n","# 가중치는 require_grad라는 속성 값을 가지고 있는데 이 값을 False로 설정하면 모델 학습시 이 가중치는 학습하지 않음.\n","# for param in model.features.parameters():\n","#     param.require_grad = False"],"metadata":{"id":"G6wP-l0SwDwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 출력층을 1개의 노드를 가진 전결합층으로 교체\n","\n","model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(classes))\n","\n","\n","\n","## 모델의 연산을 그래픽 카드에서 하도록 설정\n","print(model.to('cuda'))"],"metadata":{"id":"XwWiwRFSwDzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model 클래스 개수\n","model.classifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8E6SIN3e-YQO","executionInfo":{"status":"ok","timestamp":1685626299345,"user_tz":-540,"elapsed":2,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"02dea42a-6e80-4ab6-a0de-1389a6f32e1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Dropout(p=0.2, inplace=False)\n","  (1): Linear(in_features=1280, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001,\n","                      momentum=0.9)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"],"metadata":{"id":"ebNeVllvwD2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training\n","def train(epoch, model, criterion, optimizer):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()*inputs.size(0)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels).sum().item()\n","\n","    epoch_loss = train_loss/total\n","    epoch_acc = correct/total*100\n","    print(\"Train | Loss:%.4f Acc: %.2f%% (%s/%s)\"\n","        % (epoch_loss, epoch_acc, correct, total))\n","    return epoch_loss, epoch_acc\n","\n","def test(epoch, model, criterion, optimizer):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, labels) in enumerate(testloader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            test_loss += loss.item()*inputs.size(0)\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","\n","        epoch_loss = test_loss/total\n","        epoch_acc = correct/total*100\n","        print(\"Test | Loss:%.4f Acc: %.2f%% (%s/%s)\"\n","            % (epoch_loss, epoch_acc, correct, total))\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"6e84T9N_wD4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start_time = time.time()\n","best_acc = 0\n","epoch_length = 100\n","save_loss = {\"train\":[],\n","             \"test\":[]}\n","save_acc = {\"train\":[],\n","             \"test\":[]}\n","for epoch in range(epoch_length):\n","    print(\"Epoch %s\" % epoch)\n","    train_loss, train_acc = train(epoch, model, criterion, optimizer)\n","    save_loss['train'].append(train_loss)\n","    save_acc['train'].append(train_acc)\n","\n","    test_loss, test_acc = test(epoch, model, criterion, optimizer)\n","    save_loss['test'].append(test_loss)\n","    save_acc['test'].append(test_acc)\n","\n","    scheduler.step()\n","\n","    # Save model\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","    model.load_state_dict(best_model_wts)\n","\n","learning_time = time.time() - start_time\n","print(f'**Learning time: {learning_time // 60:.0f}m {learning_time % 60:.0f}s')"],"metadata":{"id":"5LLLLhBwwD7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(save_acc['train'])\n","plt.plot(save_acc['test'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"oNaJxc6HwCzf","executionInfo":{"status":"ok","timestamp":1685626961545,"user_tz":-540,"elapsed":349,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"39491f84-7bb5-4062-87d1-b3893faced80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f56b10f1300>]"]},"metadata":{},"execution_count":53},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"g389JMUonFuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cGTfHCpS4YPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wg1VMgKb4YSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KlukVIBy4YU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a0Ogp6hj4YXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision import datasets, models\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","from tqdm.notebook import tqdm"],"metadata":{"id":"dRFtKGZT37Nj","executionInfo":{"status":"ok","timestamp":1687397675868,"user_tz":-540,"elapsed":365,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","# Define your custom dataset path and image transformations\n","data_dir = \"/content/drive/MyDrive/bungae_images_v3/\"\n","image_size = 224  # Adjust the size according to your requirements\n","\n","data_transforms = {\n","    \"train\": transforms.Compose([\n","        transforms.RandomResizedCrop(image_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    \"val\": transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.CenterCrop(image_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Load the custom dataset using the ImageFolder class\n","image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x])\n","                  for x in [\"train\", \"val\"]}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=4)\n","               for x in [\"train\", \"val\"]}\n","dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n","class_names = image_datasets[\"train\"].classes\n"],"metadata":{"id":"rvOqSOZyOx9Y","executionInfo":{"status":"ok","timestamp":1687397816163,"user_tz":-540,"elapsed":137795,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load the pretrained MobileNetV2 model\n","model = models.mobilenet_v2(pretrained=True)\n","num_classes = len(class_names)\n","\n","# Modify the last fully connected layer of the model\n","model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n","\n","# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Freeze initial layers and train only the later layers\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9cWJAiWvEek","executionInfo":{"status":"ok","timestamp":1687397821509,"user_tz":-540,"elapsed":5352,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"cf1f43d1-7551-4c1d-fb37-7a02a99bd07e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 224MB/s]\n"]}]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10  # Adjust the number of epochs as needed\n","\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","\n","for epoch in tqdm(range(num_epochs)):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(\"-\" * 10)\n","\n","    for phase in [\"train\", \"val\"]:\n","        if phase == \"train\":\n","            model.train()\n","        else:\n","            model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            with torch.set_grad_enabled(phase == \"train\"):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward pass and optimization only in training phase\n","                if phase == \"train\":\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        if phase == \"train\":\n","            scheduler.step()\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        if phase == \"train\":\n","            train_losses.append(epoch_loss)\n","            train_accs.append(epoch_acc)\n","        else:\n","            val_losses.append(epoch_loss)\n","            val_accs.append(epoch_acc)\n","\n","        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n","\n","# Access the accuracy and loss values from the lists\n","print(\"Train Losses:\", train_losses)\n","print(\"Train Accuracies:\", train_accs)\n","print(\"Validation Losses:\", val_losses)\n","print(\"Validation Accuracies:\", val_accs)\n"],"metadata":{"id":"lzCS_TeSvHSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -- squeezenet --"],"metadata":{"id":"VK-OkEgNv4IU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, models\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","from tqdm import tqdm\n","import os\n","from PIL import Image\n","import numpy as np\n","import torchvision.transforms as transforms"],"metadata":{"id":"U69dc__mEp7d","executionInfo":{"status":"ok","timestamp":1687408337431,"user_tz":-540,"elapsed":6812,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# # Define your custom dataset path and image transformations\n","# data_dir = \"/content/drive/MyDrive/bungae_images_v3/\"\n","# image_size = 224  # Adjust the size according to your requirements\n","# resized_image_size = 128  # Adjust the size for preprocessing\n","\n","# data_transforms = {\n","#     \"train\": transforms.Compose([\n","#         transforms.Resize(resized_image_size),\n","#         transforms.RandomResizedCrop(image_size),\n","#         transforms.RandomHorizontalFlip(),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","#     ]),\n","#     \"val\": transforms.Compose([\n","#         transforms.Resize(resized_image_size),\n","#         transforms.CenterCrop(image_size),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","#     ]),\n","# }\n","\n","# # Load the custom dataset using the ImageFolder class with preprocessed images\n","# image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x])\n","#                   for x in [\"train\", \"val\"]}\n","# dataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=4)\n","#                for x in [\"train\", \"val\"]}\n","# dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n","# class_names = image_datasets[\"train\"].classes\n","\n","# # Rest of the code remains unchanged...\n"],"metadata":{"id":"K-hWvAIeQdyQ","executionInfo":{"status":"ok","timestamp":1687406710378,"user_tz":-540,"elapsed":257999,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","\n","# Define your custom dataset path and image transformations\n","data_dir = \"/content/drive/MyDrive/bungae_images_v3/\"\n","image_size = 224  # Adjust the size according to your requirements\n","\n","# Preprocess the images and save them in a separate directory\n","preprocessed_dir = \"/content/drive/MyDrive/v3_bungae_preprocessed_images/\"\n","os.makedirs(preprocessed_dir, exist_ok=True)\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.CenterCrop(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","for phase in [\"train\", \"val\"]:\n","    phase_dir = os.path.join(preprocessed_dir, phase)\n","    os.makedirs(phase_dir, exist_ok=True)\n","\n","    for filename in tqdm(os.listdir(os.path.join(data_dir, phase))):\n","        if filename.startswith('.'):\n","            continue  # Skip hidden files\n","\n","        image_path = os.path.join(data_dir, phase, filename)\n","\n","        try:\n","            label = int(filename.split(\"_\")[0])\n","        except ValueError:\n","            continue  # Skip files with invalid labels\n","\n","        try:\n","            image = Image.open(image_path)\n","            image = data_transforms(image)\n","\n","            # Save the preprocessed image as numpy array\n","            preprocessed_image_path = os.path.join(phase_dir, filename.split(\".\")[0] + \".npy\")\n","            np.save(preprocessed_image_path, image.numpy())\n","\n","        except OSError:\n","            continue  # Skip files that cannot be opened as images\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy7VFxaqXVbq","executionInfo":{"status":"ok","timestamp":1687409305751,"user_tz":-540,"elapsed":132755,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"d23d2b34-8604-4dd3-b0fa-607ddf5c6c0a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 158/158 [01:36<00:00,  1.64it/s]\n","100%|██████████| 157/157 [00:35<00:00,  4.46it/s]\n"]}]},{"cell_type":"code","source":["# Load the preprocessed dataset using a custom dataset class\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.samples = self._load_samples()\n","\n","    def _load_samples(self):\n","        samples = []\n","        for phase in [\"train\", \"val\"]:\n","            phase_dir = os.path.join(self.data_dir, phase)\n","            for filename in os.listdir(phase_dir):\n","                if filename.endswith(\".npy\"):\n","                    image_path = os.path.join(phase_dir, filename)\n","                    label = int(filename.split(\"_\")[0])\n","                    samples.append((image_path, label))\n","        return samples\n","\n","    def __getitem__(self, index):\n","        image_path, label = self.samples[index]\n","        image = np.load(image_path)\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","# Load the preprocessed dataset using the CustomDataset class\n","preprocessed_datasets = {x: CustomDataset(preprocessed_dir, transform=data_transforms[x])\n","                         for x in [\"train\", \"val\"]}\n","dataloaders = {x: DataLoader(preprocessed_datasets[x], batch_size=64, shuffle=True, num_workers=4)\n","               for x in [\"train\", \"val\"]}\n","dataset_sizes = {x: len(preprocessed_datasets[x]) for x in [\"train\", \"val\"]}\n","class_names = image_datasets[\"train\"].classes\n"],"metadata":{"id":"k1mwGYmJYAq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the pretrained SqueezeNet model\n","model = models.squeezenet1_1(pretrained=True)\n","num_classes = len(class_names)\n","\n","# Modify the classifier of the model\n","model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n","model.num_classes = num_classes\n","\n","# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Freeze initial layers and train only the later layers\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUaeZbUHEubt","executionInfo":{"status":"ok","timestamp":1687406715540,"user_tz":-540,"elapsed":5187,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"471949a4-5f95-4525-c819-e19ee71f98c0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n","100%|██████████| 4.73M/4.73M [00:00<00:00, 75.1MB/s]\n"]}]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10  # Adjust the number of epochs as needed\n","\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","\n","for epoch in tqdm(range(num_epochs)):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(\"-\" * 10)\n","\n","    for phase in [\"train\", \"val\"]:\n","        if phase == \"train\":\n","            model.train()\n","        else:\n","            model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            with torch.set_grad_enabled(phase == \"train\"):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward pass and optimization only in training phase\n","                if phase == \"train\":\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        if phase == \"train\":\n","            scheduler.step()\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        if phase == \"train\":\n","            train_losses.append(epoch_loss)\n","            train_accs.append(epoch_acc)\n","        else:\n","            val_losses.append(epoch_loss)\n","            val_accs.append(epoch_acc)\n","\n","        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n","\n","# Access the accuracy and loss values from the lists\n","print(\"Train Losses:\", train_losses)\n","print(\"Train Accuracies:\", train_accs)\n","print(\"Validation Losses:\", val_losses)\n","print(\"Validation Accuracies:\", val_accs)\n"],"metadata":{"id":"PfMs0gN6EwXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x0WdqKY9cz6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6Vl1_I8Bcz3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, models\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","from tqdm import tqdm\n","import os\n","from PIL import Image\n","import numpy as np\n","import torchvision.transforms as transforms"],"metadata":{"id":"1878VpC8cz0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","\n","# Define your custom dataset path and image transformations\n","data_dir = \"/content/drive/MyDrive/bungae_images_v3/\"\n","image_size = 224  # Adjust the size according to your requirements\n","\n","# Preprocess the images and save them in a separate directory\n","preprocessed_dir = \"/content/drive/MyDrive/v3_bungae_preprocessed_images/\"\n","os.makedirs(preprocessed_dir, exist_ok=True)\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.CenterCrop(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","for phase in [\"train\", \"val\"]:\n","    phase_dir = os.path.join(preprocessed_dir, phase)\n","    os.makedirs(phase_dir, exist_ok=True)\n","\n","    for filename in tqdm(os.listdir(os.path.join(data_dir, phase))):\n","        if filename.startswith('.'):\n","            continue  # Skip hidden files\n","\n","        image_path = os.path.join(data_dir, phase, filename)\n","\n","        try:\n","            label = int(filename.split(\"_\")[0])\n","        except ValueError:\n","            continue  # Skip files with invalid labels\n","\n","        try:\n","            image = Image.open(image_path)\n","            image = data_transforms(image)\n","\n","            # Save the preprocessed image as numpy array\n","            preprocessed_image_path = os.path.join(phase_dir, filename.split(\".\")[0] + \".npy\")\n","            np.save(preprocessed_image_path, image.numpy())\n","\n","        except OSError:\n","            continue  # Skip files that cannot be opened as images\n"],"metadata":{"id":"EqJdoAEaczw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the preprocessed dataset using a custom dataset class\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.samples = self._load_samples()\n","\n","    def _load_samples(self):\n","        samples = []\n","        for phase in [\"train\", \"val\"]:\n","            phase_dir = os.path.join(self.data_dir, phase)\n","            for filename in os.listdir(phase_dir):\n","                if filename.endswith(\".npy\"):\n","                    image_path = os.path.join(phase_dir, filename)\n","                    label = int(filename.split(\"_\")[0])\n","                    samples.append((image_path, label))\n","        return samples\n","\n","    def __getitem__(self, index):\n","        image_path, label = self.samples[index]\n","        image = np.load(image_path)\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","# Define the transformations for train and val phases\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Update with your normalization values\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Update with your normalization values\n","])\n","\n","# Load the preprocessed dataset using the CustomDataset class\n","preprocessed_datasets = {\n","    \"train\": CustomDataset(preprocessed_dir, transform=train_transform),\n","    \"val\": CustomDataset(preprocessed_dir, transform=val_transform)\n","}\n","\n","# Debug: Print the number of samples in each phase\n","for phase in [\"train\", \"val\"]:\n","    print(f\"{phase} samples: {len(preprocessed_datasets[phase])}\")\n","\n","dataloaders = {\n","    \"train\": DataLoader(preprocessed_datasets[\"train\"], batch_size=64, shuffle=True, num_workers=4),\n","    \"val\": DataLoader(preprocessed_datasets[\"val\"], batch_size=64, shuffle=True, num_workers=4)\n","}\n","\n","dataset_sizes = {x: len(preprocessed_datasets[x]) for x in [\"train\", \"val\"]}\n","class_names = list(range(num_classes))  # Update class_names to a list of labels\n","\n","\n","# Modify the classifier of the model\n","model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n","model.num_classes = num_classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"r1G2EFeMcztx","executionInfo":{"status":"error","timestamp":1687409803954,"user_tz":-540,"elapsed":430,"user":{"displayName":"WonBin Choi","userId":"10208743129506063448"}},"outputId":"7558d2b3-a0cc-4441-a123-07b7f81578b6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["train samples: 0\n","val samples: 0\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a824ae9fd5ef>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m dataloaders = {\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m }\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m    108\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"]}]},{"cell_type":"code","source":["# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Freeze initial layers and train only the later layers\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n","\n"],"metadata":{"id":"DhQU69_eczqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10  # Adjust the number of epochs as needed\n","\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","\n","for epoch in tqdm(range(num_epochs)):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    print(\"-\" * 10)\n","\n","    for phase in [\"train\", \"val\"]:\n","        if phase == \"train\":\n","            model.train()\n","        else:\n","            model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            with torch.set_grad_enabled(phase == \"train\"):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward pass and optimization only in training phase\n","                if phase == \"train\":\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        if phase == \"train\":\n","            scheduler.step()\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        if phase == \"train\":\n","            train_losses.append(epoch_loss)\n","            train_accs.append(epoch_acc)\n","        else:\n","            val_losses.append(epoch_loss)\n","            val_accs.append(epoch_acc)\n","\n","        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n","\n","# Access the accuracy and loss values from the lists\n","print(\"Train Losses:\", train_losses)\n","print(\"Train Accuracies:\", train_accs)\n","print(\"Validation Losses:\", val_losses)\n","print(\"Validation Accuracies:\", val_accs)\n"],"metadata":{"id":"w5XPkBDrczm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IlzMxt9IczjR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4NAfKWstczfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gW81nRzLczIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -- mobileNet V3 small --"],"metadata":{"id":"S_dNWgFoE8bV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision import datasets, models\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","from tqdm.notebook import tqdm\n"],"metadata":{"id":"Wky6LgTzGNen"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your custom dataset path and image transformations\n","data_dir = \"/content/drive/MyDrive/bungae_images_v3/\"\n","image_size = 224  # Adjust the size according to your requirements\n","\n","data_transforms = {\n","    \"train\": transforms.Compose([\n","        transforms.RandomResizedCrop(image_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    \"val\": transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.CenterCrop(image_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Load the custom dataset using the ImageFolder class\n","image_datasets = {x: datasets.ImageFolder(root=data_dir, transform=data_transforms[x])\n","                  for x in [\"train\", \"val\"]}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=4)\n","               for x in [\"train\", \"val\"]}\n","dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n","class_names = image_datasets[\"train\"].classes\n"],"metadata":{"id":"4bbzh7TBGPoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the pretrained MobileNetV3-Small model\n","model = models.mobilenet_v3_small(pretrained=True)\n","num_classes = len(class_names)\n","\n","# Modify the classifier of the model\n","model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n","\n","# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Freeze initial layers and train only the later layers\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n"],"metadata":{"id":"RnTo9CriGSqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10  # Adjust the number of epochs as needed\n","\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","\n","for epoch in tqdm(range(num_epochs)):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(\"-\" * 10)\n","\n","    for phase in [\"train\", \"val\"]:\n","        if phase == \"train\":\n","            model.train()\n","        else:\n","            model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            with torch.set_grad_enabled(phase == \"train\"):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                # Backward pass and optimization only in training phase\n","                if phase == \"train\":\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        if phase == \"train\":\n","            scheduler.step()\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        if phase == \"train\":\n","            train_losses.append(epoch_loss)\n","            train_accs.append(epoch_acc)\n","        else:\n","            val_losses.append(epoch_loss)\n","            val_accs.append(epoch_acc)\n","\n","        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n","\n","# Access the accuracy and loss values from the lists\n","print(\"Train Losses:\", train_losses)\n","print(\"Train Accuracies:\", train_accs)\n","print(\"Validation Losses:\", val_losses)\n","print(\"Validation Accuracies:\", val_accs)\n"],"metadata":{"id":"yGi3cOsNGUy_"},"execution_count":null,"outputs":[]}]}