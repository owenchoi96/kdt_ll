{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 사전작업"
      ],
      "metadata": {
        "id": "PEfbaqUPMchg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- mecab 설치 --\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "!pip3 install mecab-python3\n",
        "!pip install konlpy\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "IyQVSKVXkeLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install portalocker>=2.0.0"
      ],
      "metadata": {
        "id": "zwjqbmR-Wwev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def bring_and_preprocess_df():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/bungae_image_df.csv', encoding='utf-8-sig')\n",
        "    df = df.dropna(axis=0)\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['cat_id'] = df['cat_id'].astype(int).astype(str)\n",
        "    return df\n",
        "\n",
        "df = bring_and_preprocess_df()\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuOadhUcMcBW",
        "outputId": "81cc2de5-54da-43fd-9900-e76bcd3f242a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1391022, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch code"
      ],
      "metadata": {
        "id": "G6Chrl3jMeUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5gq78Jdh6J2E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "import transformers\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bigrams(x):\n",
        "    \"\"\"\n",
        "    bi-gram 생성 함수\n",
        "    \"\"\"\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "    for n_gram in n_grams:\n",
        "        x.append(' '.join(n_gram))\n",
        "    return x\n",
        "\n",
        "def remove_punct(text):\n",
        "    \"\"\"\n",
        "    문장기호 없애는 함수\n",
        "    \"\"\"\n",
        "    remove_punct_dict = dict((ord(punct), ' ') for punct in string.punctuation)\n",
        "    text = text.lower().translate(remove_punct_dict)\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    \"\"\"\n",
        "    data.Field에 사용될 tokenizer 함수\n",
        "    \"\"\"\n",
        "    mecab = Mecab()\n",
        "    text = remove_punct(text)\n",
        "    tokens = mecab.nouns(text)\n",
        "    tokens = [token for token in tokens if len(token) >1]\n",
        "    return tokens\n",
        "\n",
        "# -- koelectra tokenizer --\n",
        "model_path = 'monologg/koelectra-base-v3-discriminator'\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "trLIGOTJ6KYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- CustomDataset 베이스 코드 --\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, text, label, tokenizer=None, preprocessing=None):\n",
        "        # -- 데이터셋의 전처리를 해주는 부분 --\n",
        "        self.text = text\n",
        "        self.label = label # 여기 부분 어떻게?\n",
        "        self.tokenizer = tokenizer\n",
        "        self.preprocessing = generate_bigrams\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # -- 데이터셋에서 특정 1개의 샘플을 가져오는 함수 -- \n",
        "        text = self.text[index]\n",
        "        \n",
        "        label = self.label[index]\n",
        "        \n",
        "        if self.tokenizer is not None:\n",
        "            tokens = self.tokenizer(text)\n",
        "        \n",
        "        if self.preprocessing is not None:\n",
        "            data = self.preprocessing(tokens)\n",
        "\n",
        "        return data, label\n",
        "        \n",
        "    def __len__(self):\n",
        "        # -- 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분 --\n",
        "        return len(self.text)"
      ],
      "metadata": {
        "id": "quEo6vQn6KdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "metadata": {
        "id": "7xdGLuMJKPTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -- train_df와 test_df 이전에 나누어주기 -- \n",
        "class BungaeDataset(Dataset):\n",
        "    def __init__(self, tokenizer=None, preprocessing=None):\n",
        "        # -- 데이터셋의 전처리를 해주는 부분 --\n",
        "        df = bring_and_preprocess_df()\n",
        "\n",
        "        self.data = df['product_name']\n",
        "        self.labels = df['cat_id']\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.preprocessing = generate_bigrams\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # -- 데이터셋에서 특정 1개의 샘플을 가져오는 함수 -- \n",
        "        data = self.data[index]\n",
        "        label = self.labels[index]\n",
        "    \n",
        "        tokens = self.tokenizer(text, \n",
        "                                # padding=True, truncation=True, max_length=32\n",
        "                                )\n",
        "        data = self.preprocessing(tokens)\n",
        "\n",
        "        return data, label\n",
        "        \n",
        "    def __len__(self):\n",
        "        # -- 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분 --\n",
        "        return len(self.labels)\n",
        "\n",
        "dataset_bungae = BungaeDataset(tokenizer=tokenizer, preprocessing=generate_bigrams)"
      ],
      "metadata": {
        "id": "rOIpg8Ko6Kfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with ChatGPT"
      ],
      "metadata": {
        "id": "Rg_TqkEB6Kp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "def generate_bigrams(x):\n",
        "    \"\"\"\n",
        "    bi-gram 생성 함수\n",
        "    \"\"\"\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "    for n_gram in n_grams:\n",
        "        x.append(' '.join(n_gram))\n",
        "    return x\n",
        "\n",
        "def remove_punct(text):\n",
        "    \"\"\"\n",
        "    문장기호 없애는 함수\n",
        "    \"\"\"\n",
        "    remove_punct_dict = dict((ord(punct), ' ') for punct in string.punctuation)\n",
        "    text = text.lower().translate(remove_punct_dict)\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    \"\"\"\n",
        "    data.Field에 사용될 tokenizer 함수\n",
        "    \"\"\"\n",
        "    mecab = Mecab()\n",
        "    text = remove_punct(text)\n",
        "    tokens = mecab.nouns(text)\n",
        "    tokens = [token for token in tokens if len(token) >1]\n",
        "    return tokens\n",
        "\n",
        "# -- koelectra tokenizer --\n",
        "model_path = 'monologg/koelectra-base-v3-discriminator'\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "vSlUDx_gg5o0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- train_df와 test_df 나누기 --\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['product_name'], df['cat_id'].values, shuffle=True, test_size=.2)\n",
        "train_df = df.iloc[x_train.index]\n",
        "test_df = df.iloc[x_test.index]\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "5Z7_gklKd6Rp",
        "outputId": "dad4e6b3-96c7-479a-81b5-f25ec1961dc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         product_id                   product_name  \\\n",
              "1319949   178523724                     일꼬르소 바지 82   \n",
              "718988    210988907             JPN 빈티지 갈피 퍼 후드 자켓   \n",
              "557721    223587526    1169)챔피온 패턴 폴리반바지 남성 34인치권장   \n",
              "1208754   193520347  쏭스튜디오 LUCKY SHOULDER BAG MINI   \n",
              "1152336   219683896                          남성 자켓   \n",
              "...             ...                            ...   \n",
              "528201    221503022     [ XL ] 빈폴 남성 로고 울 싱글 패딩 코트   \n",
              "416342    224602344                         나이키테크팩   \n",
              "185317    183321485         앤아더스토리즈 청바지 EUR25 가격내림   \n",
              "950528    225058767                  시스템 바지 여성32인치   \n",
              "392526    222462858             쿠어 코듀로이 패널드 라운딩 팬츠   \n",
              "\n",
              "                                                 image_url  image_cnt  \\\n",
              "1319949  https://media.bunjang.co.kr/product/178523724_...        2.0   \n",
              "718988   https://media.bunjang.co.kr/product/210988907_...        2.0   \n",
              "557721   https://media.bunjang.co.kr/product/223587526_...        5.0   \n",
              "1208754  https://media.bunjang.co.kr/product/193520347_...        3.0   \n",
              "1152336  https://media.bunjang.co.kr/product/219683896_...        6.0   \n",
              "...                                                    ...        ...   \n",
              "528201   https://media.bunjang.co.kr/product/221503022_...        8.0   \n",
              "416342   https://media.bunjang.co.kr/product/224602344_...        3.0   \n",
              "185317   https://media.bunjang.co.kr/product/183321485_...        6.0   \n",
              "950528   https://media.bunjang.co.kr/product/225058767_...       12.0   \n",
              "392526   https://media.bunjang.co.kr/product/222462858_...        1.0   \n",
              "\n",
              "            cat_id  \n",
              "1319949  320120100  \n",
              "718988   320090999  \n",
              "557721   320130999  \n",
              "1208754  430200300  \n",
              "1152336  320100200  \n",
              "...            ...  \n",
              "528201   320080700  \n",
              "416342   320150200  \n",
              "185317   310140999  \n",
              "950528   310150010  \n",
              "392526   320120100  \n",
              "\n",
              "[1112817 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8a8e190-0d17-4844-aa8f-8074459e4f34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>image_url</th>\n",
              "      <th>image_cnt</th>\n",
              "      <th>cat_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1319949</th>\n",
              "      <td>178523724</td>\n",
              "      <td>일꼬르소 바지 82</td>\n",
              "      <td>https://media.bunjang.co.kr/product/178523724_...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>320120100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718988</th>\n",
              "      <td>210988907</td>\n",
              "      <td>JPN 빈티지 갈피 퍼 후드 자켓</td>\n",
              "      <td>https://media.bunjang.co.kr/product/210988907_...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>320090999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557721</th>\n",
              "      <td>223587526</td>\n",
              "      <td>1169)챔피온 패턴 폴리반바지 남성 34인치권장</td>\n",
              "      <td>https://media.bunjang.co.kr/product/223587526_...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>320130999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208754</th>\n",
              "      <td>193520347</td>\n",
              "      <td>쏭스튜디오 LUCKY SHOULDER BAG MINI</td>\n",
              "      <td>https://media.bunjang.co.kr/product/193520347_...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>430200300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1152336</th>\n",
              "      <td>219683896</td>\n",
              "      <td>남성 자켓</td>\n",
              "      <td>https://media.bunjang.co.kr/product/219683896_...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>320100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528201</th>\n",
              "      <td>221503022</td>\n",
              "      <td>[ XL ] 빈폴 남성 로고 울 싱글 패딩 코트</td>\n",
              "      <td>https://media.bunjang.co.kr/product/221503022_...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>320080700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416342</th>\n",
              "      <td>224602344</td>\n",
              "      <td>나이키테크팩</td>\n",
              "      <td>https://media.bunjang.co.kr/product/224602344_...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>320150200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185317</th>\n",
              "      <td>183321485</td>\n",
              "      <td>앤아더스토리즈 청바지 EUR25 가격내림</td>\n",
              "      <td>https://media.bunjang.co.kr/product/183321485_...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>310140999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950528</th>\n",
              "      <td>225058767</td>\n",
              "      <td>시스템 바지 여성32인치</td>\n",
              "      <td>https://media.bunjang.co.kr/product/225058767_...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>310150010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392526</th>\n",
              "      <td>222462858</td>\n",
              "      <td>쿠어 코듀로이 패널드 라운딩 팬츠</td>\n",
              "      <td>https://media.bunjang.co.kr/product/222462858_...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>320120100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1112817 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a8e190-0d17-4844-aa8f-8074459e4f34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8a8e190-0d17-4844-aa8f-8074459e4f34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8a8e190-0d17-4844-aa8f-8074459e4f34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "\n",
        "data = list(df['product_name'])\n",
        "# -- tokenizing --\n",
        "tokenized_data = [tokenizer(text) for text in data]\n",
        "flattened_data = [word for text in tokenized_data for word in text]\n",
        "\n",
        "# -- build the vocabulary -- \n",
        "vocabulary = torchtext.vocab.build_vocab_from_iterator([flattened_data])"
      ],
      "metadata": {
        "id": "_uYb91V9Rslm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer, preprocessing):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        label = self.labels[index]\n",
        "        tokens = self.tokenizer(data, \n",
        "                                # padding=True, truncation=True, max_length=32\n",
        "                                )\n",
        "        data = self.preprocessing(tokens)\n",
        "\n",
        "        sample = {\n",
        "            'data': data,\n",
        "            'label': label\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have your own data and labels\n",
        "\n",
        "# Create the train dataset\n",
        "train_data = list(train_df['product_name'])\n",
        "train_labels = list(train_df['cat_id'])\n",
        "train_dataset = CustomDataset(train_data, train_labels, tokenizer, generate_bigrams)\n",
        "\n",
        "# Create the test dataset\n",
        "test_data = list(test_df['product_name'])\n",
        "test_labels = list(test_df['cat_id'])\n",
        "test_dataset = CustomDataset(test_data, test_labels, tokenizer, generate_bigrams)\n",
        "\n",
        "# Create the data loader\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "num_workers = 2\n",
        "drop_last=True\n",
        "\n",
        "# train dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
        "                         num_workers=num_workers, drop_last=drop_last)\n",
        "# test dataloader\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle,\n",
        "                         num_workers=num_workers, drop_last=drop_last)\n"
      ],
      "metadata": {
        "id": "-oYg_xbU6KsH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchtext\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the pre-trained embeddings\n",
        "embedding_file = '/content/drive/MyDrive/wiki.ko.vec'\n",
        "embeddings = torchtext.vocab.Vectors(embedding_file)\n",
        "\n",
        "embeddings_tensor = torch.Tensor(embeddings.vectors)\n",
        "embedding_dim = embeddings.dim\n",
        "\n",
        "class FastText(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, embeddings):\n",
        "        super(FastText, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings)\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)  # shape: (batch_size, sequence_length, embedding_dim)\n",
        "        embedded = embedded.permute(1, 0, 2) \n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1],1)).squeeze(1) \n",
        "        return self.fc(pooled)\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have your own dataset and vocabulary\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = len(embeddings.itos)\n",
        "embedding_dim = 300\n",
        "num_classes = len(df['cat_id'].unique())\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "# Create model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FastText(vocab_size, embedding_dim, num_classes, embeddings_tensor).to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc = accuracy_score(predicted.cpu(), batch_labels.cpu())\n",
        "        print(f\"Accuracy: {acc}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_inputs, batch_labels in test_loader:\n",
        "            # move data to GPU\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            outputs = model(batch_inputs)\n",
        "            _, predicted = torch.max(outputs.data, dim=1)\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels).sum().item()\n",
        "        \n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "rvhOiHa66Ku1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "c0ff7a2f-807f-432a-f14a-cc1ef7b841fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c617b141b151>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    }
  ]
}