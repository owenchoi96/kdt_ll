{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033452e3",
   "metadata": {},
   "source": [
    "***번개장터 데이터 가져오기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ceb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def concat_bungae_files():\n",
    "    base_df = pd.DataFrame()\n",
    "    for idx in range(9):\n",
    "        df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
    "        df = df.dropna(axis=0)\n",
    "        df['cat_id'] = df['cat_id'].astype(int).astype(str)\n",
    "        # -- 필요한 컬럼만 가져오기 -- \n",
    "        df = df[['product_id', 'product_name', 'cat_id']].copy()\n",
    "        # -- concat 할 때마다 base_df 업데이트 -- \n",
    "        base_df = pd.concat([base_df, df], ignore_index=True)\n",
    "\n",
    "    # -- base_df 드라이브에 저장해놓기 --\n",
    "    # base_df.to_csv('/content/drive/MyDrive/bungae_base_df_fashion.csv', index=False)\n",
    "\n",
    "    return base_df\n",
    "\n",
    "\n",
    "sample_df = concat_bungae_files()\n",
    "sample_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec4703",
   "metadata": {},
   "source": [
    "# 베이스 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 예시로 여성 패딩 카테고리만 가져와보기 --\n",
    "# 310090050 롱패딩\n",
    "# 310090060 숏패딩\n",
    "# 310090020 블루종/항공점퍼\n",
    "df = sample_df[sample_df['cat_id'].isin(['310090050', '310090060', '310090020'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 전처리 --\n",
    "# -- 기호 없애기 --\n",
    "text = 'bcbg 정품 오리털패딩(택포)'\n",
    "import string\n",
    "def remove_punct(text):\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "    text = text.lower().translate(remove_punct_dict)\n",
    "    return text\n",
    "\n",
    "df['product_name'] = df['product_name'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256c5c7",
   "metadata": {},
   "source": [
    "***Word2Vec, FastText 활용하지 않기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"활용 X\"\"\"\n",
    "# from gensim.models import Word2Vec\n",
    "# from gensim.models.fasttext import FastText\n",
    "# from konlpy.tag import Mecab\n",
    "# import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9340ca",
   "metadata": {},
   "source": [
    "**숏패딩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312150a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = df[df['cat_id'] == '310090060'].copy()\n",
    "short = short.reset_index(drop=True).copy()\n",
    "short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_filtered = short[~short['product_name'].str.contains('롱|항공|블루종')].copy()\n",
    "short_filtered = short_filtered['product_name'][short_filtered['product_name'].str.contains('숏')].copy()\n",
    "print(len(short_filtered))\n",
    "short_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d741281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d95528",
   "metadata": {},
   "source": [
    "**롱패딩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb921c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "long = df[df['cat_id'] == '310090050'].copy()\n",
    "long = long.reset_index(drop=True).copy()\n",
    "long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30791796",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_filtered = long[~long['product_name'].str.contains('숏|항공|블루종')].copy()\n",
    "long_filtered = long_filtered['product_name'][long_filtered['product_name'].str.contains('롱')].copy()\n",
    "print(len(long_filtered))\n",
    "long_filtered.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d4912",
   "metadata": {},
   "source": [
    "**항공점퍼|블루종**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hangong = df[df['cat_id'] == '310090020'].copy()\n",
    "hangong = hangong.reset_index(drop=True).copy()\n",
    "hangong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5557e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hangong_filtered = hangong[~hangong['product_name'].str.contains('숏|롱')].copy()\n",
    "hangong_filtered = hangong_filtered['product_name'][hangong_filtered['product_name'].str.contains('항공|블루종')].copy()\n",
    "print(len(hangong_filtered))\n",
    "hangong_filtered.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac905d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-- 여기까지 여성의류 > 패딩 > 숏패딩, 롱패딩, 항공점퍼|블루종 예시 --\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae35c78",
   "metadata": {},
   "source": [
    "# 전체 카테고리에 대한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "def concat_bungae_files():\n",
    "    base_df = pd.DataFrame()\n",
    "    for idx in range(9):\n",
    "        df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
    "        df = df.dropna(axis=0)\n",
    "        df['cat_id'] = df['cat_id'].astype(int).astype(str)\n",
    "        # -- 필요한 컬럼만 가져오기 -- \n",
    "        df = df[['product_id', 'product_name', 'cat_id']].copy()\n",
    "        # -- concat 할 때마다 base_df 업데이트 -- \n",
    "        base_df = pd.concat([base_df, df], ignore_index=True)\n",
    "\n",
    "    # -- base_df 드라이브에 저장해놓기 --\n",
    "    # base_df.to_csv('/content/drive/MyDrive/bungae_base_df_fashion.csv', index=False)\n",
    "\n",
    "    return base_df\n",
    "\n",
    "# -- 전처리 --\n",
    "# -- 기호 없애기 --\n",
    "def remove_punct(text):\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "    text = text.lower().translate(remove_punct_dict)\n",
    "    return text\n",
    "\n",
    "def bring_fashion_cat_csv():\n",
    "    \"\"\"\n",
    "    번개장터 카테고리 id와 카테고리 이름이 들어있는\n",
    "    파일 가져오는 함수\n",
    "    \"\"\"\n",
    "    final_cat = pd.read_csv('./final_category.csv')\n",
    "    final_cat = final_cat.drop('Unnamed: 0', axis=1).copy()\n",
    "    final_cat['cat_id'] = final_cat['cat_id'].astype(str)\n",
    "    \n",
    "    return final_cat\n",
    "\n",
    "def get_cat_name(cat_id:str) -> str:\n",
    "    \"\"\"\n",
    "    카테고리 id를 입력하면 카테고리 이름을 반환하는 함수 => 중분류에 대해서\n",
    "    \"\"\"\n",
    "    final_cat = bring_fashion_cat_csv()\n",
    "    if len(cat_id) == 6: # 중분류\n",
    "        return list(final_cat[final_cat['cat_id'] == cat_id]['cat2'])[0]\n",
    "    elif len(cat_id) == 9: # 대분류\n",
    "        return list(final_cat[final_cat['cat_id'] == cat_id]['cat3'])[0]\n",
    "\n",
    "# -- subs 가 있는 것들만 dictionary로 뽑아내기 --\n",
    "def make_category_dict_with_subs() -> dict:\n",
    "    \n",
    "    with open('./bgzt_fashion_category_nums.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    category_dict_with_subs = dict()\n",
    "    for main, mids in data.items():\n",
    "        for mid, subs in mids.items():\n",
    "            d = defaultdict()\n",
    "            if subs != [None]: # 하위 sub들이 있을 때 \n",
    "                d[mid] = subs\n",
    "            category_dict_with_subs.update(d)\n",
    "    return category_dict_with_subs\n",
    "\n",
    "\n",
    "# -- 중분류 내에서의 소분류 morphs 키워드 가져오는 함수 --\n",
    "def make_subcat_morphs_by_midcat(cat_dict:dict) -> dict:\n",
    "    \"\"\"\n",
    "    make_category_dict_with_subs 함수로 부터 받은 딕션어리로\n",
    "    midcat의 하위 subcat들의 morphs 키워드 가져오는 함수 \n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for mid, subs in cat_dict.items():\n",
    "        tmp_dict = dict()\n",
    "        for sub in subs:\n",
    "\n",
    "            mid_morph = mecab.morphs(get_cat_name(mid))\n",
    "            sub_morph = mecab.morphs(remove_punct(get_cat_name(sub)))\n",
    "            unique_sub_morph = set(sub_morph) - set(mid_morph)\n",
    "            unique_sub_morph = list(unique_sub_morph)\n",
    "            if unique_sub_morph == []:\n",
    "                d[mid] += sub_morph\n",
    "            d[mid] += unique_sub_morph\n",
    "\n",
    "    return dict(d)\n",
    "\n",
    "# -- 위의 두 함수 합치기 --\n",
    "def get_dict_from_midcat_with_subs():\n",
    "    cat_dict = make_category_dict_with_subs()\n",
    "    morphs_dict = make_subcat_morphs_by_midcat(cat_dict)\n",
    "    return morphs_dict\n",
    "\n",
    "\n",
    "# -- 다음으로는 mid만 있는 것들만 뽑아내기 --\n",
    "def make_category_lists_without_subs():\n",
    "    \"\"\"\n",
    "    소분류 카테고리가 없는 중분류 리스트 => cat_ids_without_subs\n",
    "    \"\"\"\n",
    "    # -- 패션 cat_id 들어있는 json 파일 가져오기 --\n",
    "    with open('./bgzt_fashion_category_nums.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    cat_list_without_subs = list()\n",
    "    morphs_list = list()\n",
    "    for main, mids in data.items():\n",
    "        for mid in mids:\n",
    "            if mids[mid] == [None]:\n",
    "                morphs_list += mecab.morphs(remove_punct(get_cat_name(mid)))\n",
    "                cat_list_without_subs.append(mid)\n",
    "    \n",
    "    morphs_list = list(set(morphs_list))\n",
    "    \n",
    "    return morphs_list, cat_list_without_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea44d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- 카테고리 번호가 9인, 즉 sub 카테고리가 있는 상품들에 대해 \n",
    "def make_df_for_nine_nums_cat_ids():\n",
    "    sample_df = concat_bungae_files()\n",
    "    morphs_dict_with_subs = get_dict_from_midcat_with_subs()\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    for cat_id in list(sample_df['cat_id'].unique()):\n",
    "        if len(cat_id) == 9:\n",
    "            try:\n",
    "                tmp_df = sample_df[sample_df['cat_id'] == cat_id]\n",
    "                cat_id_morphs = mecab.morphs(remove_punct(get_cat_name(cat_id)))\n",
    "                mid_id_name = mecab.morphs(remove_punct(get_cat_name(cat_id[:6])))\n",
    "                midcat_morphs = morphs_dict_with_subs[cat_id[:6]]\n",
    "\n",
    "                cat_id_morphs = [morph for morph in cat_id_morphs if morph in midcat_morphs]\n",
    "                other_morphs = [morph for morph in midcat_morphs if morph not in cat_id_morphs]\n",
    "                opposite_keywords = '|'.join(other_morphs)\n",
    "\n",
    "                tmp_df_filtered = tmp_df[~tmp_df['product_name'].str.contains(opposite_keywords)]\n",
    "\n",
    "                if '기타' in cat_id_morphs:\n",
    "                    df = tmp_df_filtered\n",
    "                else:\n",
    "                    if '긴팔' in cat_id_morphs:\n",
    "                        cat_id_morphs += ['롱']\n",
    "                    elif '반팔' in cat_id_morphs:\n",
    "                        cat_id_morphs += ['숏']    \n",
    "                    else:\n",
    "                        cat_id_morphs = cat_id_morphs\n",
    "                    df = tmp_df_filtered[tmp_df_filtered['product_name'].str.contains('|'.join(cat_id_morphs))]\n",
    "                    \n",
    "                final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    return final_df\n",
    "\n",
    "def make_df_for_six_num_ids():\n",
    "    morphs_list_without_subs, cat_list_without_subs = make_category_lists_without_subs()\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    for cat_id in list(sample_df['cat_id'].unique()):\n",
    "        if cat_id in cat_list_without_subs:\n",
    "            \n",
    "            tmp_df = sample_df[sample_df['cat_id'] == cat_id].copy()\n",
    "            cat_id_morphs = mecab.morphs(remove_punct(get_cat_name(cat_id)))\n",
    "\n",
    "            mid_id_name = mecab.morphs(remove_punct(get_cat_name(cat_id[:6])))\n",
    "            other_morphs = [morph for morph in morphs_list_without_subs if morph not in cat_id_morphs]\n",
    "            opposite_keywords = '|'.join(other_morphs)\n",
    "\n",
    "            tmp_df_filtered = tmp_df[~tmp_df['product_name'].str.contains(opposite_keywords)].copy()\n",
    "\n",
    "            if '기타' in cat_id_morphs:\n",
    "                df = tmp_df_filtered\n",
    "            else:\n",
    "                df = tmp_df_filtered[tmp_df_filtered['product_name'].str.contains('|'.join(cat_id_morphs))].copy()\n",
    "                \n",
    "            final_df = pd.concat([final_df, df])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "def concat_two_df(): \n",
    "    final_df1 = make_df_for_nine_nums_cat_ids()\n",
    "    final_df2 = make_df_for_six_num_ids()\n",
    "    df = pd.concat([final_df1, final_df2], ignore_index=True)\n",
    "    return df # 대략 반개 줄어들음 \n",
    "\n",
    "final_df = concat_two_df()\n",
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_df['product_name_length'] = final_df['product_name'].apply(lambda x : len(x))\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_df['product_name_length'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['cat_id'].value_counts().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_id_count = final_df['cat_id'].value_counts()\n",
    "plt.bar(height = cat_id_count, x= cat_id_count.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237a0b8",
   "metadata": {},
   "source": [
    "# FastText로 진행해보기?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f2908",
   "metadata": {},
   "source": [
    "- FastText를 통해서 진행을 했을때 관련이 없는 단어들이 나오긴 했지만 <br>\n",
    "그래도 해당 단어들로 데이터들을 모았을 때 대략 (데이터가 너무 적은 카테고리를 빼고) <br>\n",
    "500~3000 사이로 들어오는 것 같음\n",
    "- 그래서 해당 방법으로 데이터를 모아보기\n",
    "- 하나의 가설로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def get_df_by_fasttext(cat_id:str):\n",
    "    df = sample_df[sample_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    tokenizer = Mecab()\n",
    "\n",
    "    tokens = []\n",
    "    for idx in range(len(df)):\n",
    "        token = tokenizer.morphs(df.loc[idx]['product_name'])\n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- fasttext training --       \n",
    "    for _ in range(20):\n",
    "        model2 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "        model2.build_vocab(tokens)\n",
    "        total_examples = model2.corpus_count\n",
    "        model2.train(tokens, total_examples=model2.corpus_count, epochs=10)\n",
    "        \n",
    "    # -- get most similar words -- \n",
    "    results = model2.wv.most_similar(positive=['스키니', '진'], negative=['일자', '부츠', '컷', '배기', '기타'], topn=20)\n",
    "    keywords_list = [result[0] for result in results]\n",
    "    keywords = str('|'.join(keywords_list))\n",
    "    print(keywords)\n",
    "    \n",
    "    \n",
    "    # -- get df --\n",
    "    df_filtered = df[df['product_name'].str.contains(keywords)]\n",
    "    \n",
    "    del model2\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b131f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_df_by_fasttext('310140010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords_list:\n",
    "    for token in tokens:\n",
    "        if keyword in token:\n",
    "            print(keyword, token)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24febe02",
   "metadata": {},
   "source": [
    "***전처리 후 진행***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 전처리 함수 -- \n",
    "import re\n",
    "\n",
    "def remove_punct(text: str) -> str:\n",
    "    remove_punct_dict = dict((ord(punct), ' ') for punct in string.punctuation)\n",
    "    text = text.lower().translate(remove_punct_dict)\n",
    "    return text\n",
    "\n",
    "def remove_english_and_numbers(text: str) -> str:\n",
    "    text = re.sub('[a-zㄱ-ㅎ0-9]', '', text).strip()\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocessing_product_name(product_name: str) -> str:\n",
    "    product_name = remove_punct(product_name)\n",
    "    product_name = remove_english_and_numbers(product_name)\n",
    "    return product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e98108",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df = sample_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df['product_name'] = fashion_df['product_name'].apply(lambda x : preprocessing_product_name(x))\n",
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038a2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fashion_df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca58126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_df_by_fasttext_test_version(cat_id:str, positive:list, negative:list):\n",
    "    df = fashion_df[fashion_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    tokenizer = Mecab()\n",
    "\n",
    "    tokens = []\n",
    "    for idx in range(len(df)): # 명사인 토큰만 가져오기 \n",
    "        token = [pos[0] for pos in mecab.pos(df.loc[idx]['product_name']) if pos[1][0] == 'N']            \n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- fasttext training --       \n",
    "    for _ in range(20):\n",
    "        model2 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "        model2.build_vocab(tokens)\n",
    "        total_examples = model2.corpus_count\n",
    "        model2.train(tokens, total_examples=model2.corpus_count, epochs=10)\n",
    "        \n",
    "    # -- get most similar words -- \n",
    "    results = model2.wv.most_similar(positive=positive, negative=negative, topn=20)\n",
    "    keywords_list = [result[0] for result in results]\n",
    "    keywords = str('|'.join(keywords_list))\n",
    "    print(keywords)\n",
    "    \n",
    "    \n",
    "    # -- get df --\n",
    "    df_filtered = df[df['product_name'].str.contains(keywords)]\n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    del model2\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered.sample(30)\n",
    "\n",
    "get_df_by_fasttext_test_version('320140400', ['정장', '세트'], ['자켓', '베스트', '바지', '기타'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00c658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_df_by_fasttext_test_version2(cat_id:str, positive:list, negative:list):\n",
    "    df = fashion_df[fashion_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    tokenizer = Mecab()\n",
    "\n",
    "    tokens = []\n",
    "    for idx in range(len(df)): # 명사인 토큰만 가져오기 \n",
    "        token = [pos[0] for pos in mecab.pos(df.loc[idx]['product_name']) if pos[1][0] == 'N']            \n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- model 1 training --       \n",
    "    model1 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "    model1.build_vocab(tokens)\n",
    "    total_examples1 = model1.corpus_count\n",
    "    model1.train(tokens, total_examples=total_examples1, epochs=10)\n",
    "    \n",
    "    # -- model 2 training --\n",
    "    model2 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "    model2.build_vocab(tokens)\n",
    "    total_examples2 = model2.corpus_count\n",
    "    model2.train(tokens, total_examples=total_examples2, epochs=10)\n",
    "        \n",
    "    # -- get most similar words -- \n",
    "    results1 = model1.wv.most_similar(positive=positive, topn=20)\n",
    "    results2 = model2.wv.most_similar(positive=negative, topn=20)\n",
    "    \n",
    "    keywords_list1 = [result[0] for result in results1]\n",
    "    keywords_list2 = [result[0] for result in results2]\n",
    "    \n",
    "    keywords1 = str('|'.join(keywords_list1))\n",
    "    keywords2 = str('|'.join(keywords_list2))\n",
    "    \n",
    "    print(keywords1)\n",
    "    print(keywords2)\n",
    "    \n",
    "    \n",
    "    # -- get df --\n",
    "    df1 = df[df['product_name'].str.contains(keywords1)]\n",
    "    df2 = df[df['product_name'].str.contains(keywords2)]\n",
    "    idx_list = list(set(df1.index) - set(df2.index))\n",
    "    df_filtered = df.iloc[idx_list]\n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    del model1, model2\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "get_df_by_fasttext_test_version2('320110500', ['배기', '청바지'], ['일자', '스키니', '진', '부츠', '컷','기타'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_by_fasttext_test_version3(cat_id:str, positive:list, negative=None):\n",
    "    df = fashion_df[fashion_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    tokenizer = Mecab()\n",
    "\n",
    "    tokens = []\n",
    "    for idx in range(len(df)): # 명사인 토큰만 가져오기 \n",
    "        token = [pos[0] for pos in mecab.pos(df.loc[idx]['product_name']) if pos[1][0] == 'N']            \n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- model 1 training --       \n",
    "    model1 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "    model1.build_vocab(tokens)\n",
    "    total_examples1 = model1.corpus_count\n",
    "    model1.train(tokens, total_examples=total_examples1, epochs=10)\n",
    "    \n",
    "    # -- get most similar words -- \n",
    "    results1 = model1.wv.most_similar(positive=positive, topn=20)\n",
    "    keywords_list1 = [result[0] for result in results1]\n",
    "    keywords1 = str('|'.join(keywords_list1))\n",
    "    print(keywords1)\n",
    "    \n",
    "    # -- 반대되는 데이터 프레임 --\n",
    "    if negative != None:\n",
    "        opposite_keywords = '|'.join(negative)\n",
    "        df = df[~df['product_name'].str.contains(opposite_keywords)].copy()\n",
    "    \n",
    "    # -- get df --\n",
    "    df_filtered = df[df['product_name'].str.contains(keywords1)]\n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    del model1\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "get_df_by_fasttext_test_version3('310110030', ['겨울', '코트'], ['봄', '가을'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a91737",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab.morphs('맨투맨')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ea50c",
   "metadata": {},
   "source": [
    "# 버전 3로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26810f1",
   "metadata": {},
   "source": [
    "해당 작업 목표를 다시 상기하면 <br>\n",
    "- 데이터가 너무 많아서 모델 학습 시간이 오래 걸려 데이터 수를 줄이고자 하였고,\n",
    "- 데이터를 줄일 때 최대한 해당 카테고리별와 연관이 있는 데이터를 가져오고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d05c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/nt9qv8x55mv3g666qst4sx980000gn/T/ipykernel_68555/1555314315.py:25: DtypeWarning: Columns (0,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
      "/var/folders/yr/nt9qv8x55mv3g666qst4sx980000gn/T/ipykernel_68555/1555314315.py:25: DtypeWarning: Columns (0,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
      "/var/folders/yr/nt9qv8x55mv3g666qst4sx980000gn/T/ipykernel_68555/1555314315.py:25: DtypeWarning: Columns (0,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n"
     ]
    }
   ],
   "source": [
    "# -- 전처리 함수 -- \n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "def remove_punct(text: str) -> str:\n",
    "    remove_punct_dict = dict((ord(punct), ' ') for punct in string.punctuation)\n",
    "    text = text.lower().translate(remove_punct_dict)\n",
    "    return text\n",
    "\n",
    "def remove_english_and_numbers(text: str) -> str:\n",
    "    text = re.sub('[a-zㄱ-ㅎ0-9]', '', text).strip()\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_product_name(product_name: str) -> str:\n",
    "    product_name = remove_punct(product_name)\n",
    "    product_name = remove_english_and_numbers(product_name)\n",
    "    return product_name\n",
    "\n",
    "# -- 전체 데이터 프레임 가져오는 함수 --\n",
    "def concat_bungae_files():\n",
    "    base_df = pd.DataFrame()\n",
    "    for idx in range(9):\n",
    "        df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
    "        df = df.dropna(axis=0)\n",
    "        df['cat_id'] = df['cat_id'].astype(int).astype(str)\n",
    "        # -- 필요한 컬럼만 가져오기 -- \n",
    "        df = df[['product_id', 'product_name', 'cat_id']].copy()\n",
    "        # -- concat 할 때마다 base_df 업데이트 -- \n",
    "        base_df = pd.concat([base_df, df], ignore_index=True)\n",
    "\n",
    "    # -- base_df 드라이브에 저장해놓기 --\n",
    "    # base_df.to_csv('/content/drive/MyDrive/bungae_base_df_fashion.csv', index=False)\n",
    "\n",
    "    return base_df\n",
    "\n",
    "def pull_and_preprocess_base_df():\n",
    "    base_df = concat_bungae_files()\n",
    "    base_df['product_name'] = base_df['product_name'].apply(lambda x : preprocess_product_name(x))\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63976a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bring_fashion_cat_csv():\n",
    "    \"\"\"\n",
    "    번개장터 카테고리 id와 카테고리 이름이 들어있는\n",
    "    파일 가져오는 함수\n",
    "    \"\"\"\n",
    "    final_cat = pd.read_csv('./final_category.csv')\n",
    "    final_cat = final_cat.drop('Unnamed: 0', axis=1).copy()\n",
    "    final_cat['cat_id'] = final_cat['cat_id'].astype(str)\n",
    "    \n",
    "    return final_cat\n",
    "\n",
    "def get_cat_name(cat_id:str) -> str:\n",
    "    \"\"\"\n",
    "    카테고리 id를 입력하면 카테고리 이름을 반환하는 함수 => 중분류에 대해서\n",
    "    \"\"\"\n",
    "    final_cat = bring_fashion_cat_csv()\n",
    "    if len(cat_id) == 6: # 중분류\n",
    "        return remove_punct(list(final_cat[final_cat['cat_id'] == cat_id]['cat2'])[0])\n",
    "    elif len(cat_id) == 9: # 대분류\n",
    "        return remove_punct(list(final_cat[final_cat['cat_id'] == cat_id]['cat3'])[0])\n",
    "\n",
    "# -- subs 가 있는 것들만 dictionary로 뽑아내기 --\n",
    "def make_category_dict_with_subs() -> dict:\n",
    "    \n",
    "    with open('./bgzt_fashion_category_nums.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    category_dict_with_subs = dict()\n",
    "    for main, mids in data.items():\n",
    "        for mid, subs in mids.items():\n",
    "            d = defaultdict()\n",
    "            if subs != [None]: # 하위 sub들이 있을 때 \n",
    "                d[mid] = subs\n",
    "            category_dict_with_subs.update(d)\n",
    "    return category_dict_with_subs\n",
    "\n",
    "\n",
    "# -- 중분류 내에서의 소분류 morphs 키워드 가져오는 함수 --\n",
    "def make_subcat_morphs_by_midcat(cat_dict:dict) -> dict:\n",
    "    \"\"\"\n",
    "    make_category_dict_with_subs 함수로 부터 받은 딕션어리로\n",
    "    midcat의 하위 subcat들의 morphs 키워드 가져오는 함수 \n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for mid, subs in cat_dict.items():\n",
    "        tmp_dict = dict()\n",
    "        for sub in subs:\n",
    "\n",
    "            mid_morph = mecab.morphs(get_cat_name(mid))\n",
    "            sub_morph = mecab.morphs(remove_punct(get_cat_name(sub)))\n",
    "            unique_sub_morph = set(sub_morph) - set(mid_morph)\n",
    "            unique_sub_morph = list(unique_sub_morph)\n",
    "            if unique_sub_morph == []:\n",
    "                d[mid] += sub_morph\n",
    "            d[mid] += unique_sub_morph\n",
    "\n",
    "    return dict(d)\n",
    "\n",
    "# -- 위의 두 함수 합치기 --\n",
    "def get_dict_from_midcat_with_subs():\n",
    "    cat_dict = make_category_dict_with_subs()\n",
    "    morphs_dict = make_subcat_morphs_by_midcat(cat_dict)\n",
    "    return morphs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fc1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from gensim.models.fasttext import FastText\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "def get_df_by_fasttext_test_version3(cat_id:str):\n",
    "    \n",
    "    # -- 카테고리 id에 맞는 데이터 프레임 가져오기 --\n",
    "    df = fashion_df[fashion_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    mecab = Mecab()\n",
    "    tokens = []\n",
    "    for idx in range(len(df)): # 명사인 토큰만 가져오기 \n",
    "        token = [pos[0] for pos in mecab.pos(df.loc[idx]['product_name']) if pos[1][0] == 'N']            \n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- model 1 training --       \n",
    "    model1 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "    model1.build_vocab(tokens)\n",
    "    total_examples1 = model1.corpus_count\n",
    "    model1.train(tokens, total_examples=total_examples1, epochs=10)\n",
    "    \n",
    "    # -- get most similar words -- \n",
    "    cat_name_morphs = mecab.morphs(get_cat_name(cat_id))\n",
    "    mid_name_morphs = mecab.morphs(get_cat_name(cat_id[:6]))\n",
    "    cat_name_morphs = list(set(cat_name_morphs) - set(mid_name_morphs))\n",
    "    print(get_cat_name(cat_id))\n",
    "    \n",
    "    results = model1.wv.most_similar(positive=cat_name_morphs, topn=30)\n",
    "    keywords_list = [result[0] for result in results]\n",
    "    keywords = str('|'.join(keywords_list))\n",
    "    \n",
    "    # -- 반대되는 데이터 프레임 --\n",
    "    # -- category id가 9개 자리수인 것만 소분류 내에서 다른 카테고리 키워드 들어간 데이터 삭제해주기 -- \n",
    "    cat_id_keywords_dict = get_dict_from_midcat_with_subs()\n",
    "    if len(cat_id) == 9:\n",
    "        keyword_list = cat_id_keywords_dict[cat_id[:6]]\n",
    "        opposites = list(set(keyword_list) - set(cat_name_morphs))\n",
    "        opposite_keywords = '|'.join(opposites)\n",
    "        df = df[~df['product_name'].str.contains(opposite_keywords)].copy()\n",
    "    \n",
    "    # -- get df --\n",
    "    df_filtered = df[df['product_name'].str.contains(keywords)]\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    \n",
    "    if len(df_filtered) > 400:\n",
    "        df_filtered = df_filtered.sample(400)\n",
    "    \n",
    "    del model1\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbcfd5ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduce_data():\n",
    "    \n",
    "    base_df = pull_and_preprocess_base_df()\n",
    "    fashion_df = base_df.copy()\n",
    "    \n",
    "    cat_id_list = list(fashion_df['cat_id'].unique())\n",
    "    final_df = pd.DataFrame()\n",
    "    for cat_id in cat_id_list:\n",
    "        try:\n",
    "            df = get_df_by_fasttext_test_version3(cat_id)\n",
    "            final_df = pd.concat([final_df, df])\n",
    "        except:\n",
    "            pass\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed316827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223861589</td>\n",
       "      <td>노스페이스 롱패딩</td>\n",
       "      <td>310090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211498059</td>\n",
       "      <td>새상품 뉴발란스 베스트 블랙 패딩</td>\n",
       "      <td>310090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210612980</td>\n",
       "      <td>정품 빈폴 구스다운</td>\n",
       "      <td>310090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223417908</td>\n",
       "      <td>새상품급 정품 얇은 고급 패딩 착샷 통통</td>\n",
       "      <td>310090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211768829</td>\n",
       "      <td>네파 롱패딩 팝니다 가격내림</td>\n",
       "      <td>310090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57094</th>\n",
       "      <td>174798546</td>\n",
       "      <td>방울털모자 겨울모자</td>\n",
       "      <td>400070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57095</th>\n",
       "      <td>164895194</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57096</th>\n",
       "      <td>220016723</td>\n",
       "      <td>노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈</td>\n",
       "      <td>400070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57097</th>\n",
       "      <td>113371163</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57098</th>\n",
       "      <td>156328453</td>\n",
       "      <td>라탄 벙거지 모자</td>\n",
       "      <td>400070999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57099 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                  product_name     cat_id\n",
       "0      223861589                     노스페이스 롱패딩  310090050\n",
       "1      211498059            새상품 뉴발란스 베스트 블랙 패딩  310090050\n",
       "2      210612980                    정품 빈폴 구스다운  310090050\n",
       "3      223417908        새상품급 정품 얇은 고급 패딩 착샷 통통  310090050\n",
       "4      211768829               네파 롱패딩 팝니다 가격내림  310090050\n",
       "...          ...                           ...        ...\n",
       "57094  174798546                    방울털모자 겨울모자  400070999\n",
       "57095  164895194                            모자  400070999\n",
       "57096  220016723  노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈  400070999\n",
       "57097  113371163                            모자  400070999\n",
       "57098  156328453                     라탄 벙거지 모자  400070999\n",
       "\n",
       "[57099 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c624195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import core\n",
    "def remove_emojis(text):\n",
    "    return core.replace_emoji(text, replace='')\n",
    "\n",
    "# -- label encoding --\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(final_df['cat_id'])\n",
    "final_df['label'] = labels\n",
    "\n",
    "final_df['product_name'] = final_df['product_name'].apply(lambda x : remove_emojis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d501da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223861589</td>\n",
       "      <td>노스페이스 롱패딩</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211498059</td>\n",
       "      <td>새상품 뉴발란스 베스트 블랙 패딩</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210612980</td>\n",
       "      <td>정품 빈폴 구스다운</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223417908</td>\n",
       "      <td>새상품급 정품 얇은 고급 패딩 착샷 통통</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211768829</td>\n",
       "      <td>네파 롱패딩 팝니다 가격내림</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57094</th>\n",
       "      <td>174798546</td>\n",
       "      <td>방울털모자 겨울모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57095</th>\n",
       "      <td>164895194</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57096</th>\n",
       "      <td>220016723</td>\n",
       "      <td>노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57097</th>\n",
       "      <td>113371163</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57098</th>\n",
       "      <td>156328453</td>\n",
       "      <td>라탄 벙거지 모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57099 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                  product_name     cat_id  label\n",
       "0      223861589                     노스페이스 롱패딩  310090050     16\n",
       "1      211498059            새상품 뉴발란스 베스트 블랙 패딩  310090050     16\n",
       "2      210612980                    정품 빈폴 구스다운  310090050     16\n",
       "3      223417908        새상품급 정품 얇은 고급 패딩 착샷 통통  310090050     16\n",
       "4      211768829               네파 롱패딩 팝니다 가격내림  310090050     16\n",
       "...          ...                           ...        ...    ...\n",
       "57094  174798546                    방울털모자 겨울모자  400070999    112\n",
       "57095  164895194                            모자  400070999    112\n",
       "57096  220016723  노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈  400070999    112\n",
       "57097  113371163                            모자  400070999    112\n",
       "57098  156328453                     라탄 벙거지 모자  400070999    112\n",
       "\n",
       "[57099 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c80e66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  60, 128, ..., 104, 144,  19])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(final_df['product_name'],\n",
    "                                                    final_df['label'].values, \n",
    "                                                    random_state=5, \n",
    "                                                    test_size=.2)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8387b6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223861589</td>\n",
       "      <td>노스페이스 롱패딩</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211498059</td>\n",
       "      <td>새상품 뉴발란스 베스트 블랙 패딩</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210612980</td>\n",
       "      <td>정품 빈폴 구스다운</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223417908</td>\n",
       "      <td>새상품급 정품 얇은 고급 패딩 착샷 통통</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211768829</td>\n",
       "      <td>네파 롱패딩 팝니다 가격내림</td>\n",
       "      <td>310090050</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57094</th>\n",
       "      <td>174798546</td>\n",
       "      <td>방울털모자 겨울모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57095</th>\n",
       "      <td>164895194</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57096</th>\n",
       "      <td>220016723</td>\n",
       "      <td>노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57097</th>\n",
       "      <td>113371163</td>\n",
       "      <td>모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57098</th>\n",
       "      <td>156328453</td>\n",
       "      <td>라탄 벙거지 모자</td>\n",
       "      <td>400070999</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57099 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                  product_name     cat_id  label\n",
       "0      223861589                     노스페이스 롱패딩  310090050     16\n",
       "1      211498059            새상품 뉴발란스 베스트 블랙 패딩  310090050     16\n",
       "2      210612980                    정품 빈폴 구스다운  310090050     16\n",
       "3      223417908        새상품급 정품 얇은 고급 패딩 착샷 통통  310090050     16\n",
       "4      211768829               네파 롱패딩 팝니다 가격내림  310090050     16\n",
       "...          ...                           ...        ...    ...\n",
       "57094  174798546                    방울털모자 겨울모자  400070999    112\n",
       "57095  164895194                            모자  400070999    112\n",
       "57096  220016723  노스페이스 남성등산모자 고어텍스 여름등산모자 사이즈  400070999    112\n",
       "57097  113371163                            모자  400070999    112\n",
       "57098  156328453                     라탄 벙거지 모자  400070999    112\n",
       "\n",
       "[57099 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36d0300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = ''\n",
    "for idx in range(len(final_df)):\n",
    "    my_str += f\"{final_df.loc[idx, 'label']},{final_df.loc[idx, 'product_name']}\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36851f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_fasttext_file.txt', 'w') as f:\n",
    "    f.write(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- train, validation, test 분리하고 --\n",
    "# -- 모델 돌려보기 -- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
