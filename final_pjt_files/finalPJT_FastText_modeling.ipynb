{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12fcdf1",
   "metadata": {},
   "source": [
    "***필요한 함수들***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 전처리 함수 -- \n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from emoji import core\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return core.replace_emoji(text, replace='')\n",
    "\n",
    "def remove_punct(text: str) -> str:\n",
    "    remove_punct_dict = dict((ord(punct), ' ') for punct in string.punctuation)\n",
    "    text = text.lower().translate(remove_punct_dict)\n",
    "    return text\n",
    "\n",
    "def remove_english_and_numbers(text: str) -> str:\n",
    "    text = re.sub('[a-zㄱ-ㅎ0-9]', '', text).strip() \n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text: str) -> str:\n",
    "    text = re.sub('[ㄱ-ㅎ0-9]', '', text).strip() \n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_product_name(product_name: str) -> str:\n",
    "    product_name = remove_punct(product_name)\n",
    "    # -- 영어 날리는 버전 --\n",
    "#     product_name = remove_english_and_numbers(product_name)\n",
    "    # -- 영어 살리는 버전 --\n",
    "    product_name = remove_numbers(product_name)\n",
    "    \n",
    "    return product_name\n",
    "\n",
    "# -- 전체 데이터 프레임 가져오는 함수 --\n",
    "def concat_bungae_files():\n",
    "    base_df = pd.DataFrame()\n",
    "    for idx in range(9):\n",
    "        df = pd.read_csv(f'./bungae_df_{idx}_fashion.csv')\n",
    "        df = df.dropna(axis=0)\n",
    "        df['cat_id'] = df['cat_id'].astype(int).astype(str)\n",
    "        # -- 필요한 컬럼만 가져오기 -- \n",
    "        df = df[['product_id', 'product_name', 'cat_id']].copy()\n",
    "        # -- concat 할 때마다 base_df 업데이트 -- \n",
    "        base_df = pd.concat([base_df, df], ignore_index=True)\n",
    "\n",
    "    # -- base_df 드라이브에 저장해놓기 --\n",
    "    # base_df.to_csv('/content/drive/MyDrive/bungae_base_df_fashion.csv', index=False)\n",
    "\n",
    "    return base_df\n",
    "\n",
    "def pull_and_preprocess_base_df():\n",
    "    base_df = concat_bungae_files()\n",
    "    base_df['product_name'] = base_df['product_name'].apply(lambda x : preprocess_product_name(x))\n",
    "    base_df['product_name'] = base_df['product_name'].apply(lambda x : remove_emojis(x))\n",
    "    return base_df\n",
    "\n",
    "def bring_fashion_cat_csv():\n",
    "    \"\"\"\n",
    "    번개장터 카테고리 id와 카테고리 이름이 들어있는\n",
    "    파일 가져오는 함수\n",
    "    \"\"\"\n",
    "    final_cat = pd.read_csv('./final_category.csv')\n",
    "    final_cat = final_cat.drop('Unnamed: 0', axis=1).copy()\n",
    "    final_cat['cat_id'] = final_cat['cat_id'].astype(str)\n",
    "    \n",
    "    return final_cat\n",
    "\n",
    "def get_cat_name(cat_id:str) -> str:\n",
    "    \"\"\"\n",
    "    카테고리 id를 입력하면 카테고리 이름을 반환하는 함수 => 중분류에 대해서\n",
    "    \"\"\"\n",
    "    final_cat = bring_fashion_cat_csv()\n",
    "    if len(cat_id) == 6: # 중분류\n",
    "        return remove_punct(list(final_cat[final_cat['cat_id'] == cat_id]['cat2'])[0])\n",
    "    elif len(cat_id) == 9: # 대분류\n",
    "        return remove_punct(list(final_cat[final_cat['cat_id'] == cat_id]['cat3'])[0])\n",
    "\n",
    "# -- subs 가 있는 것들만 dictionary로 뽑아내기 --\n",
    "def make_category_dict_with_subs() -> dict:\n",
    "    \n",
    "    with open('./bgzt_fashion_category_nums.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    category_dict_with_subs = dict()\n",
    "    for main, mids in data.items():\n",
    "        for mid, subs in mids.items():\n",
    "            d = defaultdict()\n",
    "            if subs != [None]: # 하위 sub들이 있을 때 \n",
    "                d[mid] = subs\n",
    "            category_dict_with_subs.update(d)\n",
    "    return category_dict_with_subs\n",
    "\n",
    "\n",
    "# -- 중분류 내에서의 소분류 morphs 키워드 가져오는 함수 --\n",
    "def make_subcat_morphs_by_midcat(cat_dict:dict) -> dict:\n",
    "    \"\"\"\n",
    "    make_category_dict_with_subs 함수로 부터 받은 딕션어리로\n",
    "    midcat의 하위 subcat들의 morphs 키워드 가져오는 함수 \n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for mid, subs in cat_dict.items():\n",
    "        tmp_dict = dict()\n",
    "        for sub in subs:\n",
    "\n",
    "            mid_morph = mecab.morphs(get_cat_name(mid))\n",
    "            sub_morph = mecab.morphs(remove_punct(get_cat_name(sub)))\n",
    "            unique_sub_morph = set(sub_morph) - set(mid_morph)\n",
    "            unique_sub_morph = list(unique_sub_morph)\n",
    "            if unique_sub_morph == []:\n",
    "                d[mid] += sub_morph\n",
    "            d[mid] += unique_sub_morph\n",
    "\n",
    "    return dict(d)\n",
    "\n",
    "# -- 위의 두 함수 합치기 --\n",
    "def get_dict_from_midcat_with_subs():\n",
    "    cat_dict = make_category_dict_with_subs()\n",
    "    morphs_dict = make_subcat_morphs_by_midcat(cat_dict)\n",
    "    return morphs_dict\n",
    "\n",
    "def make_category_lists_without_subs():\n",
    "    \"\"\"\n",
    "    소분류 카테고리가 없는 중분류 리스트 => cat_ids_without_subs\n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    # -- 패션 cat_id 들어있는 json 파일 가져오기 --\n",
    "    with open('./bgzt_fashion_category_nums.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    cat_list_without_subs = list()\n",
    "    morphs_list = list()\n",
    "    for main, mids in data.items():\n",
    "        for mid in mids:\n",
    "            if mids[mid] == [None]:\n",
    "                morphs_list += mecab.morphs(remove_punct(get_cat_name(mid)))\n",
    "                cat_list_without_subs.append(mid)\n",
    "    \n",
    "    morphs_list = list(set(morphs_list))\n",
    "    \n",
    "    return morphs_list, cat_list_without_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba442cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_category_lists_without_subs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from gensim.models.fasttext import FastText\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "\n",
    "def get_df_by_fasttext_test_version3(fashion_df, cat_id:str):\n",
    "    \n",
    "    # -- 카테고리 id에 맞는 데이터 프레임 가져오기 --\n",
    "    df = fashion_df[fashion_df['cat_id'] == cat_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # -- tokenizing --\n",
    "    mecab = Mecab()\n",
    "    tokens = []\n",
    "    for idx in range(len(df)): # 명사인 토큰만 가져오기 \n",
    "        token = [pos[0] for pos in mecab.pos(df.loc[idx]['product_name']) if pos[1][0] == 'N']            \n",
    "        if len(token) > 1:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    # -- model 1 training --       \n",
    "    model1 = FastText(tokens, vector_size=100, window=10, min_count=5, workers=4, sg=0)\n",
    "    model1.build_vocab(tokens)\n",
    "    total_examples1 = model1.corpus_count\n",
    "    model1.train(tokens, total_examples=total_examples1, epochs=10)\n",
    "    \n",
    "    # -- get most similar words -- \n",
    "    cat_name_morphs = mecab.morphs(get_cat_name(cat_id))\n",
    "    mid_name_morphs = mecab.morphs(get_cat_name(cat_id[:6]))\n",
    "    cat_name_morphs = list(set(cat_name_morphs) - set(mid_name_morphs))\n",
    "    print(get_cat_name(cat_id))\n",
    "    \n",
    "    results = model1.wv.most_similar(positive=cat_name_morphs, topn=30)\n",
    "    keywords_list = [result[0] for result in results]\n",
    "    keywords = str('|'.join(keywords_list))\n",
    "    \n",
    "    # -- 반대되는 데이터 프레임 --\n",
    "    # -- category id가 9개 자리수인 것만 소분류 내에서 다른 카테고리 키워드 들어간 데이터 삭제해주기 -- \n",
    "    cat_id_keywords_dict = get_dict_from_midcat_with_subs()\n",
    "    if len(cat_id) == 9:\n",
    "        keyword_list = cat_id_keywords_dict[cat_id[:6]]\n",
    "        opposites = list(set(keyword_list) - set(cat_name_morphs))\n",
    "        opposite_keywords = '|'.join(opposites)\n",
    "        df = df[~df['product_name'].str.contains(opposite_keywords)].copy()\n",
    "    \n",
    "    # -- get df --\n",
    "    df_filtered = df[df['product_name'].str.contains(keywords)]\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    \n",
    "    if len(df_filtered) > 400:\n",
    "        df_filtered = df_filtered.sample(400)\n",
    "    \n",
    "    del model1\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def reduce_data():\n",
    "    \n",
    "    base_df = pull_and_preprocess_base_df()\n",
    "    fashion_df = base_df.copy()\n",
    "    \n",
    "    cat_id_list = list(fashion_df['cat_id'].unique())\n",
    "    final_df = pd.DataFrame()\n",
    "    for cat_id in cat_id_list:\n",
    "        try:\n",
    "            df = get_df_by_fasttext_test_version3(fashion_df, cat_id)\n",
    "            final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def get_and_preprocess_final_df():\n",
    "    final_df = reduce_data()\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676c6c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- 영어도 같이 포함되어 있는 버전 --\n",
    "# -- 아무래도 한국말만 쓰는 사람이 있는 것은 아니므로 --\n",
    "# -- 영어에서 그 상품에 대한 정보를 더 가져올 수 있을 것으로 예상 (ex. 사이즈) --\n",
    "final_df = get_and_preprocess_final_df()\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f20474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 한국말도 같이 있는 버전 --\n",
    "final_df2 = reduce_data()\n",
    "final_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca2b3e",
   "metadata": {},
   "source": [
    "***소분류, 중분류로만 학습시켰을 때***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['cat_id'].values, \n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "    # -- train_df, test_df 분리 --\n",
    "    train_df, test_df = df.loc[train_x.index], df.loc[test_x.index]\n",
    "    \n",
    "    # -- resetting index -- \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- making train_df txt file --\n",
    "train_df['label'] = '__label__' + train_df['cat_id']\n",
    "train_df = train_df.drop(['cat_id', 'product_id'], axis=1)\n",
    "train_df.to_csv('train_fasttext.txt', sep='\\t', index=False)\n",
    "    \n",
    "# -- making train_df txt file --\n",
    "test_df['label'] = '__label__' + test_df['cat_id']\n",
    "test_df = test_df.drop(['cat_id', 'product_id'], axis=1)\n",
    "test_df.to_csv('test_fasttext.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(input='./train_fasttext.txt', wordNgrams=3, epoch=25, \n",
    "                                  lr=0.4\n",
    "#                                   loss=\n",
    "                                  )\n",
    "# loss = hs 보다 안할때가 성능이 더 좋음. \n",
    "\n",
    "model.test('./test_fasttext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9192eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('안토니모라토 티셔츠')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e7e2a",
   "metadata": {},
   "source": [
    "# 대분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def322c5",
   "metadata": {},
   "source": [
    "***대분류로 먼저 학습시켜보기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['main_cat_id'].values,  # main_cat_id\n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "    # -- train_df, test_df 분리 --\n",
    "    train_df, test_df = df.loc[train_x.index], df.loc[test_x.index]\n",
    "    \n",
    "    # -- resetting index -- \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f640123",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['main_cat_id'] = final_df['cat_id'].apply(lambda x : x[:3])\n",
    "sample_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_test_data(sample_df)\n",
    "\n",
    "# -- making train_df txt file --\n",
    "train_df['label'] = '__label__' + train_df['main_cat_id']\n",
    "train_df = train_df.drop(['cat_id', 'product_id', 'main_cat_id'], axis=1)\n",
    "train_df.to_csv('train_fasttext_maincat.txt', sep='\\t', index=False)\n",
    "    \n",
    "# -- making train_df txt file --\n",
    "test_df['label'] = '__label__' + test_df['main_cat_id']\n",
    "test_df = test_df.drop(['cat_id', 'product_id', 'main_cat_id'], axis=1)\n",
    "test_df.to_csv('test_fasttext_maincat.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(input='./train_fasttext_maincat.txt', \n",
    "                                  wordNgrams=2, \n",
    "                                  epoch=25, \n",
    "                                  lr=0.34,\n",
    "#                                   loss='hs' # 모델 빠르게 학습 가능\n",
    "                                  loss='ova',\n",
    "                                  )\n",
    "# loss = hs 보다 안할때가 성능이 더 좋음. \n",
    "\n",
    "model.test('./test_fasttext_maincat.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('미쏘플리츠원피스')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f1a24",
   "metadata": {},
   "source": [
    "***데이터가 더 많은 전체 데이터에 대해서 학습***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b134c1",
   "metadata": {},
   "source": [
    "**FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['main_cat_id'].values,  # main_cat_id\n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "    # -- train_df, test_df 분리 --\n",
    "    train_df, test_df = df.loc[train_x.index], df.loc[test_x.index]\n",
    "    \n",
    "    # -- resetting index -- \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pull_and_preprocess_base_df()\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- base_df 자체를 가져와서 학습시켜 보기 -- \n",
    "base_df['main_cat_id'] = base_df['cat_id'].map(lambda x : x[:3])\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_test_data(base_df)\n",
    "\n",
    "# -- making train_df txt file --\n",
    "train_df['label'] = '__label__' + train_df['main_cat_id']\n",
    "train_df = train_df.drop(['cat_id', 'product_id', 'main_cat_id'], axis=1)\n",
    "train_df.to_csv('train_fasttext_maincat.txt', sep='\\t', index=False)\n",
    "    \n",
    "# -- making train_df txt file --\n",
    "test_df['label'] = '__label__' + test_df['main_cat_id']\n",
    "test_df = test_df.drop(['cat_id', 'product_id', 'main_cat_id'], axis=1)\n",
    "test_df.to_csv('test_fasttext_maincat.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(input='./train_fasttext_maincat.txt', \n",
    "                                  wordNgrams=2, \n",
    "                                  epoch=25, \n",
    "                                  lr=0.34,\n",
    "#                                   loss='hs' # 모델 빠르게 학습 가능\n",
    "                                  loss='ova',\n",
    "                                  )\n",
    "# loss = hs 보다 안할때가 성능이 더 좋음. \n",
    "\n",
    "model.test('./test_fasttext_maincat.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa62a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 용량이 적은 모델 \n",
    "model.quantize(input='./train_fasttext_maincat.txt', retrain=True)\n",
    "model.test('./test_fasttext_maincat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f49df0",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_base_df = base_df.copy()\n",
    "tf_base_df = tf_base_df.drop(['cat_id', 'product_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TF-IDF 용 --\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['main_cat_id'].values, \n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_train_test_data(tf_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ea835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), max_df=300, min_df=5)\n",
    "# -- x_train vectorization --\n",
    "X_train_cnt_vect = tfidf_vect.fit_transform(x_train)\n",
    "# -- x_test vectorization --\n",
    "X_test_cnt_vect = tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train_cnt_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print('precision_score : ', precision_score(y_test, pred, average='weighted'))\n",
    "print('recall_score : ', recall_score(y_test, pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0772549",
   "metadata": {},
   "source": [
    "# 중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55de7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['mid_cat_id'].values,  # mid_cat_id\n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "    # -- train_df, test_df 분리 --\n",
    "    train_df, test_df = df.loc[train_x.index], df.loc[test_x.index]\n",
    "    \n",
    "    # -- resetting index -- \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = base_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['mid_cat_id'] = sample_df['cat_id'].apply(lambda x : x[:6])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52608618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 여성의류 > 패딩/점퍼 --\n",
    "women = sample_df[sample_df['main_cat_id'] == '310']\n",
    "women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_train_df, women_test_df = split_train_test_data(women)\n",
    "\n",
    "# -- making train_df txt file --\n",
    "women_train_df['label'] = '__label__' + women_train_df['mid_cat_id']\n",
    "women_train_df = women_train_df.drop(['cat_id', 'product_id', 'main_cat_id', 'mid_cat_id'], axis=1)\n",
    "women_train_df.to_csv('women_train_fasttext_maincat.txt', sep='\\t', index=False)\n",
    "    \n",
    "# -- making train_df txt file --\n",
    "women_test_df['label'] = '__label__' + women_test_df['mid_cat_id']\n",
    "women_test_df = women_test_df.drop(['cat_id', 'product_id', 'main_cat_id', 'mid_cat_id'], axis=1)\n",
    "women_test_df.to_csv('women_test_fasttext_maincat.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571054be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(input='./women_train_fasttext_maincat.txt', \n",
    "                                  wordNgrams=2, \n",
    "                                  epoch=25, \n",
    "                                  lr=0.34,\n",
    "#                                   loss='hs' # 모델 빠르게 학습 가능\n",
    "                                  loss='ova',\n",
    "                                  )\n",
    "# loss = hs 보다 안할때가 성능이 더 좋음. \n",
    "\n",
    "model.test('./women_test_fasttext_maincat.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cdf57b",
   "metadata": {},
   "source": [
    "# 소분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b29ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 데이터 셋 스플릿 -- \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_data(df):\n",
    "    # -- train, test 스플릿 --\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df['product_name'],\n",
    "                                                        df['cat_id'].values,  # mid_cat_id\n",
    "                                                        random_state=5, \n",
    "                                                        test_size=.2)\n",
    "    # -- train_df, test_df 분리 --\n",
    "    train_df, test_df = df.loc[train_x.index], df.loc[test_x.index]\n",
    "    \n",
    "    # -- resetting index -- \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_padded = sample_df[sample_df['mid_cat_id'] == '310090']\n",
    "women_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25783cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_padded_train_df, women_padded_test_df = split_train_test_data(women_padded)\n",
    "\n",
    "# -- making train_df txt file --\n",
    "women_padded_train_df['label'] = '__label__' + women_padded_train_df['cat_id']\n",
    "women_padded_train_df = women_padded_train_df.drop(['cat_id', 'product_id', 'main_cat_id', 'mid_cat_id'], axis=1)\n",
    "women_padded_train_df.to_csv('women_padded_train_fasttext_maincat.txt', sep='\\t', index=False)\n",
    "    \n",
    "# -- making train_df txt file --\n",
    "women_padded_test_df['label'] = '__label__' + women_padded_test_df['cat_id']\n",
    "women_padded_test_df = women_padded_test_df.drop(['cat_id', 'product_id', 'main_cat_id', 'mid_cat_id'], axis=1)\n",
    "women_padded_test_df.to_csv('women_padded_test_fasttext_maincat.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(input='./women_padded_train_fasttext_maincat.txt', \n",
    "                                  wordNgrams=2, \n",
    "                                  epoch=25, \n",
    "                                  lr=0.34,\n",
    "#                                   loss='hs' # 모델 빠르게 학습 가능\n",
    "                                  loss='ova',\n",
    "                                  )\n",
    "# loss = hs 보다 안할때가 성능이 더 좋음. \n",
    "\n",
    "model.test('./women_padded_test_fasttext_maincat.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0c8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6821f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c9d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d50874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886d863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
